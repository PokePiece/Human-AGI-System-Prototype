# Human_AGI

A modular architecture for an artificial general intelligence (AGI) system written in C++ with Qt, Python, and embedded memory systems.  
This project defines an extensible structure for cognitive simulation, memory management, and intelligent interaction via API bridges.

## ğŸ§  Architecture Overview

Human_AGI uses a **multi-language, multi-process** architecture:

- **C++ Core (Qt GUI)**: Main control loop, decision system, and physical simulation interface.
- **Python Server (Flask)**: Hosts dynamic AI routines and memory logic.
- **ChromaDB (Python)**: Embeds and stores vectorized representations of memory for retrieval.

C++ â†” Flask (Python) â†” ChromaDB

## âœ… Features

- Modular, component-based AGI design
- Separation of C++ logic and Python cognition
- Python `VoidAGI` server for dynamic logic and memory access
- ChromaDB-backed `retrievememory.py` for vector memory embedding + retrieval
- REST API between systems (`chat` route)
- Easily extensible toward cloud integration or local-only systems

## ğŸ“ Directory Structure

/Human_AGI
â”œâ”€â”€ Brain/ # Core AGI logic in C++
â”‚ â”œâ”€â”€ VoidBrain.cpp # Main bridge to Python
â”‚ â””â”€â”€ ...
â”œâ”€â”€ Python/
â”‚ â”œâ”€â”€ VoidAGI.py # Flask server exposing the AI interface
â”‚ â””â”€â”€ retrievememory.py # Chroma memory manager
â”œâ”€â”€ Vision/ # Visual processing components
â”œâ”€â”€ Language/ # Language interface modules
â”œâ”€â”€ HumanAGI.pro # Qt project file
â””â”€â”€ main.cpp # Entry point


## âš™ï¸ Requirements

### C++

- Qt 6.0+ (e.g., Qt 6.9.1)
- C++17 compatible compiler (e.g., `mingw32-g++`)
- `qmake`, `mingw32-make`

### Python

- Python 3.10+
- `flask`
- `chromadb`
- `sentence-transformers`

Install Python dependencies:
```bash
pip install flask chromadb sentence-transformers
```
## ğŸ”¨ Build Instructions

C++ Qt Side

``` bash qmake HumanAGI.pro
mingw32-make
```
Python Server
```bash

cd Python
python VoidAGI.py
```
Make sure this Flask server is running in the background when launching the C++ executable.

## ğŸ§  Memory: ChromaDB
We use ChromaDB for embedding and retrieval of conversation or sensor history.

store_memory(text) â€” stores embedded content

retrieve_similar(text) â€” gets semantically related items from memory

Stored memory will be returned alongside AI responses for contextual grounding.

## ğŸ§ª Example Flow
User types message in C++ GUI.

C++ â†’ sends to Flask /chat route.

Flask stores message in Chroma, retrieves similar context.

AI logic executes.

Response + memory â†’ back to C++ for UI output.

## ğŸš§ Future Work
Background Python server boot via C++

Cloud sync and multi-agent communication

Lisp/Prolog interfaces for meta-reasoning

File/video/image embeddings via Chroma

Autonomy and feedback reinforcement loop